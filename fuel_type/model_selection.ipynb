{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the best model for classifying the fuel type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.api import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../assets/car-details-for-ml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the dependent variable to the end of the dataset and dropping irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seats</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>nm</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1248</td>\n",
       "      <td>74.00</td>\n",
       "      <td>190.00</td>\n",
       "      <td>450000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498</td>\n",
       "      <td>103.52</td>\n",
       "      <td>250.00</td>\n",
       "      <td>370000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1497</td>\n",
       "      <td>78.00</td>\n",
       "      <td>124.54</td>\n",
       "      <td>158000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1396</td>\n",
       "      <td>90.00</td>\n",
       "      <td>219.67</td>\n",
       "      <td>225000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1298</td>\n",
       "      <td>88.20</td>\n",
       "      <td>112.78</td>\n",
       "      <td>130000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   km_driven  seats  mileage  engine  max_power      nm  selling_price  fuel\n",
       "0     145500    5.0    23.40    1248      74.00  190.00         450000     0\n",
       "1     120000    5.0    21.14    1498     103.52  250.00         370000     0\n",
       "2     140000    5.0    17.70    1497      78.00  124.54         158000     1\n",
       "3     127000    5.0    23.00    1396      90.00  219.67         225000     0\n",
       "4     120000    5.0    16.10    1298      88.20  112.78         130000     1"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selling_price = dataset.pop('selling_price')\n",
    "\n",
    "dataset = dataset.iloc[:, :11]\n",
    "dataset.insert(len(dataset.columns), 'selling_price', selling_price)\n",
    "\n",
    "dep_variable = dataset.pop('fuel')\n",
    "dataset.insert(len(dataset.columns), 'fuel', dep_variable)\n",
    "\n",
    "dataset = dataset.drop(columns=['year', 'owner', 'transmission', 'seller_type'], axis=1)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling the data\n",
    "\n",
    "Some of the models might require the features to be scaled. Feature scaling is a common practice in machine learning and helps to normalize the features because some models are sensitive to the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23 -0.45  0.59 -0.9  -0.7  -0.98 -0.64]]\n",
      "[[-1.02 -0.45 -0.38  1.05  3.04  2.62  5.11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "# Sample the scaled values\n",
    "print(X_train_scaled[:1, :12])\n",
    "print(X_test_scaled[:1, :12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining methods for helping to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Confusion Matrix = Makes a matrix of the predictions and actual values \n",
    "# Accuracy score = Percentage of correct predictions\n",
    "\n",
    "labels = ['Model', 'Accuracy', 'Confusion Matrix']\n",
    "results = []\n",
    "\n",
    "def model_evaluation(model: str, y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results.append([model, accuracy, cm])\n",
    "    return [model, accuracy, cm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_actual_vs_predictions(y_test, y_pred):\n",
    "    np.set_printoptions(precision=2)\n",
    "    actual_vs_pred = np.concatenate((y_test.reshape(len(y_test), 1), y_pred.reshape(len(y_pred), 1)), 1)\n",
    "\n",
    "    print([\"Actual\", \"Predictions\"])\n",
    "    print(actual_vs_pred[4:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data to train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=73)"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(random_state=73)\n",
    "log_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actual', 'Predictions']\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print_actual_vs_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Logistic Regression\n",
      "Accuracy : 0.9921773142112125\n",
      "Confusion Matrix :\n",
      " [[858   7]\n",
      " [  5 664]]\n"
     ]
    }
   ],
   "source": [
    "log_reg_result = model_evaluation('Logistic Regression', y_test, y_pred)\n",
    "\n",
    "for i in range(len(log_reg_result)):\n",
    "    if (labels[i] == \"Confusion Matrix\"):\n",
    "        print(labels[i], ':\\n', log_reg_result[i])\n",
    "    else:\n",
    "        print(labels[i], ':', log_reg_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already yielding fantastic results from the first model used. Only misclassifying 0.8% of the data. Let's try and get 0% misclassification rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_class = KNeighborsClassifier(n_neighbors=3, algorithm=\"auto\")\n",
    "knn_class.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actual', 'Predictions']\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_class.predict(X_test_scaled)\n",
    "\n",
    "print_actual_vs_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : K-Nearest Neighbors Classification\n",
      "Accuracy : 0.9947848761408083\n",
      "Confusion Matrix :\n",
      " [[863   2]\n",
      " [  6 663]]\n"
     ]
    }
   ],
   "source": [
    "knn_class_result = model_evaluation('K-Nearest Neighbors Classification', y_test, y_pred)\n",
    "\n",
    "for i in range(len(knn_class_result)):\n",
    "    if (labels[i] == \"Confusion Matrix\"):\n",
    "        print(labels[i], ':\\n', knn_class_result[i])\n",
    "    else:\n",
    "        print(labels[i], ':', knn_class_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting even closer towards 0% misclassification rate. However the model is still about 0.5% off. I think we can try another model to get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=73)"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_class = DecisionTreeClassifier( random_state = 73)\n",
    "tree_class.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actual', 'Predictions']\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_class.predict(X_test_scaled)\n",
    "\n",
    "print_actual_vs_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Decision Tree Classification\n",
      "Accuracy : 0.999348109517601\n",
      "Confusion Matrix :\n",
      " [[864   1]\n",
      " [  0 669]]\n"
     ]
    }
   ],
   "source": [
    "tree_class_result = model_evaluation('Decision Tree Classification', y_test, y_pred)\n",
    "\n",
    "for i in range(len(tree_class_result)):\n",
    "    if (labels[i] == \"Confusion Matrix\"):\n",
    "        print(labels[i], ':\\n', tree_class_result[i])\n",
    "    else:\n",
    "        print(labels[i], ':', tree_class_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So close to 0% misclassification rate. Missing the mark by 1 wrong prediction. Let's try Random Forest Classification and see if we can get 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=73)"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_class = RandomForestClassifier(n_estimators=50, random_state=73)\n",
    "forest_class.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actual', 'Predictions']\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_class.predict(X_test_scaled)\n",
    "\n",
    "print_actual_vs_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Random Forest Classification\n",
      "Accuracy : 0.999348109517601\n",
      "Confusion Matrix :\n",
      " [[865   0]\n",
      " [  1 668]]\n"
     ]
    }
   ],
   "source": [
    "forest_class_result = model_evaluation('Random Forest Classification', y_test, y_pred)\n",
    "\n",
    "for i in range(len(forest_class_result)):\n",
    "    if (labels[i] == \"Confusion Matrix\"):\n",
    "        print(labels[i], ':\\n', forest_class_result[i])\n",
    "    else:\n",
    "        print(labels[i], ':', forest_class_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again missing the mark by just 1 wrong prediction. This time in False Negative instead of False Positive section. Let's try a different model and get the 0% misclassification rate."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25f971c2cafb0dc8fb6f5f8a60e926e23560cd8dfda90ca9ec85ba330e83d562"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
